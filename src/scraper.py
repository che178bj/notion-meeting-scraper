#!/usr/bin/env python3
"""
Notion æœƒè­°çˆ¬èŸ²æ ¸å¿ƒæ¨¡çµ„
"""
import re
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path

from playwright.sync_api import sync_playwright, Page, Browser

from .parser import DateParser
from .formatter import MarkdownFormatter, sanitize_filename


class MeetingScraper:
    """Notion æœƒè­°çˆ¬èŸ²"""
    
    def __init__(
        self,
        config,
        verbose: bool = True
    ):
        self.config = config
        self.verbose = verbose
        self.parser = DateParser(config.date_reference)
        self.formatter = MarkdownFormatter(config.output_date_format)
        
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        
        # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
        self.output_folder = Path(config.output_folder)
        self.output_folder.mkdir(parents=True, exist_ok=True)
    
    def log(self, message: str):
        """è¼¸å‡ºæ—¥èªŒ"""
        if self.verbose:
            print(message)
    
    def start(self):
        """å•Ÿå‹•ç€è¦½å™¨"""
        self.browser = sync_playwright().chromium.launch(headless=True)
        self.page = self.browser.new_page()
    
    def stop(self):
        """é—œé–‰ç€è¦½å™¨"""
        if self.browser:
            self.browser.close()
    
    def crawl_category(self, category: dict, reference_date: str) -> List[dict]:
        """
        çˆ¬å–å–®ä¸€åˆ†é¡
        """
        category_name = category['name']
        category_url = category['url']
        
        self.log(f"\nã€{category_name}ã€‘")
        
        # å–å¾—æ‰€æœ‰æœƒè­°é é¢ï¼ˆå«å­åˆ†é¡ï¼‰
        all_meetings = self._get_all_meetings(category_url, category_name)
        
        # éæ¿¾åªä¿ç•™ä»Šå¤©çš„æœƒè­°
        today_meetings = []
        
        for meeting in all_meetings:
            meeting_date = meeting.get('date', '')
            
            # è§£ææ—¥æœŸ
            if meeting_date:
                parsed_date = self.parser.parse(meeting_date)
                meeting['parsed_date'] = parsed_date
                
                # å–å¾— YYYY-MM-DD æ ¼å¼
                date_only = self.parser.get_date_only(meeting_date)
                meeting['date_only'] = date_only
                
                # æ¯”å°ä»Šå¤©
                if date_only == reference_date:
                    today_meetings.append(meeting)
                    self.log(f"  âœ“ ç¬¦åˆä»Šå¤©æ—¥æœŸ: {meeting.get('title', 'ç„¡æ¨™é¡Œ')[:30]}")
            else:
                # æ²’æœ‰æ—¥æœŸï¼Œå˜—è©¦å¾æ¨™é¡ŒæŠ“
                title = meeting.get('title', '')
                date_from_title = self._extract_date_from_title(title)
                if date_from_title:
                    meeting['parsed_date'] = date_from_title
                    meeting['date_only'] = date_from_title
                    
                    if date_from_title == reference_date:
                        today_meetings.append(meeting)
                        self.log(f"  âœ“ å¾æ¨™é¡Œæ‰¾åˆ°ä»Šå¤©æ—¥æœŸ: {title[:30]}")
        
        self.log(f"  â†’ ç¸½å…± {len(all_meetings)} ç­†ï¼Œç¬¦åˆä»Šå¤© {len(today_meetings)} ç­†")
        
        return today_meetings
    
    def _get_all_meetings(self, url: str, category_name: str) -> List[dict]:
        """å–å¾—æ‰€æœ‰æœƒè­°"""
        meetings = []
        
        try:
            self.page.goto(url, wait_until="domcontentloaded", timeout=self.config.crawl_timeout)
            self.page.wait_for_timeout(self.config.crawl_wait_time)
            
            # å–å¾—å­é é¢é€£çµ
            subpages = self._get_subpages()
            
            # çˆ¬å–æ¯å€‹å­é é¢
            for subpage in subpages[:self.config.crawl_max_pages]:
                try:
                    self.page.goto(subpage['url'], wait_until="domcontentloaded", timeout=self.config.crawl_timeout)
                    self.page.wait_for_timeout(self.config.crawl_wait_time)
                    
                    # å–å¾—æœƒè­°è³‡è¨Š
                    info = self._extract_meeting_info(subpage['url'])
                    
                    if info.get('title') or info.get('summary'):
                        info['category'] = category_name
                        info['subcategory'] = subpage.get('title', '')
                        meetings.append(info)
                        self.log(f"    âœ“ {info.get('title', 'ç„¡æ¨™é¡Œ')[:30]}")
                        
                except Exception as e:
                    self.log(f"    âœ— Error: {e}")
                    
        except Exception as e:
            self.log(f"  âœ— Error loading category: {e}")
        
        return meetings
    
    def _get_subpages(self) -> List[dict]:
        """å–å¾—é é¢ä¸­æ‰€æœ‰å­é é¢é€£çµ"""
        subpages = []
        
        try:
            links = self.page.evaluate('''() => {
                const result = [];
                const anchors = document.querySelectorAll('a[href*="/so/"]');
                
                anchors.forEach(anchor => {
                    const href = anchor.href;
                    const text = anchor.innerText.trim();
                    
                    if (text && text.length > 2 && text.length < 80 && href) {
                        if (!text.includes('Skip to') && !text.includes('Sign up')) {
                            result.push({ title: text, url: href });
                        }
                    }
                });
                
                return result;
            }''')
            
            # å»é‡
            seen = set()
            for link in links:
                if link['title'] not in seen:
                    seen.add(link['title'])
                    subpages.append(link)
                    
        except Exception as e:
            self.log(f"Error getting subpages: {e}")
        
        return subpages
    
    def _extract_meeting_info(self, url: str) -> dict:
        """å¾é é¢æå–æœƒè­°è³‡è¨Š"""
        result = {
            'title': '',
            'date': '',
            'summary': '',
            'notes': '',
            'url': url
        }
        
        try:
            # å–å¾—æ¨™é¡Œ
            title = self.page.evaluate('''() => {
                const heading = document.querySelector('h1');
                return heading ? heading.innerText : '';
            }''')
            result['title'] = title.strip()
            
            # å–å¾—æ—¥æœŸ
            date_text = self.page.evaluate('''() => {
                const spans = document.querySelectorAll('span');
                for (const span of spans) {
                    if (span.innerText.includes('@') && 
                        (span.innerText.includes('Last') || span.innerText.includes(', 202'))) {
                        return span.innerText.replace('@', '').trim();
                    }
                }
                return '';
            }''')
            
            if date_text:
                result['date'] = date_text.replace('@', '').strip()
            
            # å–å¾— Summary
            if self.config.extract_summary:
                summary = self.page.evaluate('''() => {
                    const allText = document.body.innerText;
                    const match = allText.match(/Summary\\s*([\\s\\S]*?)(?=Notes|$)/);
                    if (match) {
                        return match[1].trim();
                    }
                    return '';
                }''')
                result['summary'] = summary.strip()
            
            # å–å¾— Notes
            if self.config.extract_notes:
                notes = self.page.evaluate('''() => {
                    const allText = document.body.innerText;
                    const match = allText.match(/Notes\\s*([\\s\\S]*?)(?=Transcript|$)/);
                    if (match) {
                        return match[1].trim();
                    }
                    return '';
                }''')
                result['notes'] = notes.strip()
                
        except Exception as e:
            self.log(f"Error extracting info: {e}")
        
        return result
    
    def _extract_date_from_title(self, title: str) -> Optional[str]:
        """å¾æ¨™é¡Œæå–æ—¥æœŸ"""
        # å˜—è©¦æ‰¾æ—¥æœŸæ ¼å¼
        patterns = [
            r'(\d{4})/(\d{1,2})/(\d{1,2})',
            r'(\d{4})-(\d{1,2})-(\d{1,2})',
            r'(\d{1,2})/(\d{1,2})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, title)
            if match:
                try:
                    if len(match.groups()) == 3:
                        if len(match.group(1)) == 4:
                            year, month, day = match.groups()
                        else:
                            year = "2026"
                            month, day = match.group(1), match.group(2)
                        
                        date_obj = datetime(int(year), int(month), int(day))
                        return date_obj.strftime('%Y-%m-%d')
                except:
                    pass
        
        return None
    
    def save_meeting(self, meeting: dict, category: str, reference_date: str):
        """
        å„²å­˜å–®ä¸€æœƒè­°åˆ°æª”æ¡ˆ
        """
        subcategory = meeting.get('subcategory', '')
        
        # ç”¢ç”Ÿæª”å
        filename = self.formatter.generate_filename(
            category=category,
            subcategory=subcategory,
            date_str=reference_date.replace('-', ''),
            sanitize_func=sanitize_filename
        )
        
        filepath = self.output_folder / filename
        
        # æ ¼å¼åŒ–å…§å®¹
        content = self.formatter.format_meeting(
            category=category,
            subcategory=subcategory,
            date=meeting.get('parsed_date', meeting.get('date', 'æœªçŸ¥')),
            title=meeting.get('title', ''),
            summary=meeting.get('summary', ''),
            notes=meeting.get('notes', ''),
            notion_url=meeting.get('url', ''),
            crawled_at=datetime.now(),
            reference_date=reference_date
        )
        
        # å¯«å…¥æª”æ¡ˆ
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.log(f"  ğŸ’¾ å·²å„²å­˜: {filename}")
        
        return filepath
    
    def run(self, reference_date: str = None):
        """
        åŸ·è¡Œçˆ¬èŸ²
        """
        if reference_date is None:
            reference_date = self.config.date_reference
        
        self.log(f"=" * 50)
        self.log(f"Notion æœƒè­°çˆ¬èŸ² - é–‹å§‹åŸ·è¡Œ")
        self.log(f"åƒç…§æ—¥æœŸ: {reference_date}")
        self.log(f"=" * 50)
        
        self.start()
        
        saved_count = 0
        
        try:
            # éæ­·æ¯å€‹åˆ†é¡
            for category in self.config.enabled_categories:
                today_meetings = self.crawl_category(category, reference_date)
                
                # å„²å­˜ä»Šå¤©çš„æœƒè­°
                for meeting in today_meetings:
                    self.save_meeting(meeting, category['name'], reference_date)
                    saved_count += 1
                    
        finally:
            self.stop()
        
        self.log(f"\nç¸½å…±å„²å­˜ {saved_count} ç­†æœƒè­°è¨˜éŒ„")
        
        return saved_count
